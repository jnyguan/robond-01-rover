{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in ground truth map and create 3-channel green version for overplotting\n",
    "# NOTE: images are read in by default with the origin (0, 0) in the upper left\n",
    "# and y-axis increasing downward.\n",
    "ground_truth = mpimg.imread('../calibration_images/map_bw.png')\n",
    "# This next line creates arrays of zeros in the red and blue channels\n",
    "# and puts the map into the green channel.  This is why the underlying \n",
    "# map output looks green in the display image\n",
    "ground_truth_3d = np.dstack((ground_truth*0, ground_truth*255, ground_truth*0)).astype(np.float)\n",
    "\n",
    "\n",
    "# Define RoverState() class to retain rover state parameters\n",
    "class RoverState():\n",
    "    def __init__(self):\n",
    "        self.start_time = None # To record the start time of navigation\n",
    "        self.total_time = None # To record total duration of navigation\n",
    "        self.img = None # Current camera image\n",
    "        self.pos = (50, 50) # Current position (x, y)\n",
    "        self.yaw = 30 # Current yaw angle\n",
    "        self.pitch = None # Current pitch angle\n",
    "        self.roll = None # Current roll angle\n",
    "        self.vel = None # Current velocity\n",
    "        self.steer = 0 # Current steering angle\n",
    "        self.throttle = 0 # Current throttle value\n",
    "        self.brake = 0 # Current brake value\n",
    "        self.nav_angles = None # Angles of navigable terrain pixels\n",
    "        self.nav_dists = None # Distances of navigable terrain pixels\n",
    "        self.ground_truth = ground_truth_3d # Ground truth worldmap\n",
    "        self.mode = 'forward' # Current mode (can be forward or stop)\n",
    "        self.throttle_set = 0.2 # Throttle setting when accelerating\n",
    "        self.brake_set = 10 # Brake setting when braking\n",
    "        # The stop_forward and go_forward fields below represent total count\n",
    "        # of navigable terrain pixels.  This is a very crude form of knowing\n",
    "        # when you can keep going and when you should stop.  Feel free to\n",
    "        # get creative in adding new fields or modifying these!\n",
    "        self.stop_forward = 50 # Threshold to initiate stopping\n",
    "        self.go_forward = 500 # Threshold to go forward again\n",
    "        self.max_vel = 2 # Maximum velocity (meters/second)\n",
    "        # Image output from perception step\n",
    "        # Update this image to display your intermediate analysis steps\n",
    "        # on screen in autonomous mode\n",
    "        self.vision_image = np.zeros((160, 320, 3), dtype=np.float) \n",
    "        # Worldmap\n",
    "        # Update this image with the positions of navigable terrain\n",
    "        # obstacles and rock samples\n",
    "        self.worldmap = np.zeros((200, 200, 3), dtype=np.float) \n",
    "        self.samples_pos = None # To store the actual sample positions\n",
    "        self.samples_found = 0 # To count the number of samples found\n",
    "        self.near_sample = 0 # Will be set to telemetry value data[\"near_sample\"]\n",
    "        self.picking_up = 0 # Will be set to telemetry value data[\"picking_up\"]\n",
    "        self.send_pickup = False # Set to True to trigger rock pickup\n",
    "# Initialize our rover \n",
    "Rover = RoverState()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1136554e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAACFCAYAAACpMGXTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMIYiGQAAABhDkQwAAACMoUgGAAAAxvw/kFdEEqv/uG4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110079e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Identify pixels above the threshold\n",
    "# Threshold of RGB > 160 does a nice job of identifying ground pixels only\n",
    "def color_thresh(img, rgb_thresh=(160, 160, 160)):\n",
    "\n",
    "    # Create an array of zeros same xy size as img\n",
    "    # obstacle, rock samples, and navigable terrain are on different channels\n",
    "#     color_select = np.zeros_like(img[:,:,0]) \n",
    "\n",
    "    color_select_obstacle = np.zeros_like(img[:,:,0])   \n",
    "    color_select_rock = np.zeros_like(img[:,:,0])\n",
    "    color_select_nav = np.zeros_like(img[:,:,0])\n",
    "\n",
    "    # Require that each pixel be above all three threshold values in RGB\n",
    "    # above_thresh will now contain a boolean array with \"True\"\n",
    "    # where threshold was met\n",
    "    above_thresh = (img[:,:,0] > rgb_thresh[0]) \\\n",
    "                & (img[:,:,1] > rgb_thresh[1]) \\\n",
    "                & (img[:,:,2] > rgb_thresh[2])       \n",
    "            \n",
    "    above_thresh_obs = (img[:,:,0] < rgb_thresh[0]) \\\n",
    "                & (img[:,:,1] < rgb_thresh[1]) \\\n",
    "                & (img[:,:,2] < rgb_thresh[2]) \n",
    "\n",
    "    # Index the array of zeros with the boolean array and set to 1\n",
    "    color_select_obstacle[above_thresh_obs] = 1\n",
    "    color_select_rock[above_thresh] = 1\n",
    "    color_select_nav[above_thresh] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return color_select_obstacle, color_select_rock, color_select_nav\n",
    "\n",
    "# Define a function to convert to rover-centric coordinates\n",
    "def rover_coords(binary_img):\n",
    "    # Identify nonzero pixels\n",
    "    ypos, xpos = binary_img.nonzero()\n",
    "    # Calculate pixel positions with reference to the rover position being at the \n",
    "    # center bottom of the image.  \n",
    "    x_pixel = np.absolute(ypos - binary_img.shape[0]).astype(np.float)\n",
    "    y_pixel = -(xpos - binary_img.shape[0]).astype(np.float)\n",
    "    return x_pixel, y_pixel\n",
    "\n",
    "\n",
    "# Define a function to convert to radial coords in rover space\n",
    "def to_polar_coords(x_pixel, y_pixel):\n",
    "    # Convert (x_pixel, y_pixel) to (distance, angle) \n",
    "    # in polar coordinates in rover space\n",
    "    # Calculate distance to each pixel\n",
    "    dist = np.sqrt(x_pixel**2 + y_pixel**2)\n",
    "    # Calculate angle away from vertical for each pixel\n",
    "    angles = np.arctan2(y_pixel, x_pixel)\n",
    "    return dist, angles\n",
    "\n",
    "# Define a function to apply a rotation to pixel positions\n",
    "def rotate_pix(xpix, ypix, yaw):\n",
    "    # TODO:\n",
    "    # Convert yaw to radians\n",
    "    # Apply a rotation\n",
    "\n",
    "    # convert yaw angle from degrees to radians\n",
    "    yaw_rad = yaw * np.pi/180\n",
    "    \n",
    "    # perform rotation matrix\n",
    "    xpix_rotated = xpix * np.cos(yaw_rad) - ypix * np.sin(yaw_rad)\n",
    "    ypix_rotated = xpix * np.sin(yaw_rad) + ypix * np.cos(yaw_rad)\n",
    "\n",
    "    # Return the result  \n",
    "    return xpix_rotated, ypix_rotated\n",
    "\n",
    "# Define a function to perform a translation\n",
    "def translate_pix(xpix_rot, ypix_rot, xpos, ypos, scale): \n",
    "    # TODO:\n",
    "    # Apply a scaling and a translation\n",
    "\n",
    "    # perform translation and convert to integer since pixel values can't be float\n",
    "    xpix_translated = np.int_(xpos + xpix_rot / scale)\n",
    "    ypix_translated = np.int_(ypos + ypix_rot / scale)\n",
    "\n",
    "    # Return the result  \n",
    "    return xpix_translated, ypix_translated\n",
    "\n",
    "# Define a function to apply rotation and translation (and clipping)\n",
    "# Once you define the two functions above this function should work\n",
    "def pix_to_world(xpix, ypix, xpos, ypos, yaw, world_size, scale):\n",
    "    # Apply rotation\n",
    "    xpix_rot, ypix_rot = rotate_pix(xpix, ypix, yaw)\n",
    "    # Apply translation\n",
    "    xpix_tran, ypix_tran = translate_pix(xpix_rot, ypix_rot, xpos, ypos, scale)\n",
    "    # Perform rotation, translation and clipping all at once\n",
    "    x_pix_world = np.clip(np.int_(xpix_tran), 0, world_size - 1)\n",
    "    y_pix_world = np.clip(np.int_(ypix_tran), 0, world_size - 1)\n",
    "    # Return the result\n",
    "    return x_pix_world, y_pix_world\n",
    "\n",
    "# Define a function to perform a perspective transform\n",
    "def perspect_transform(img, src, dst):\n",
    "           \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    warped = cv2.warpPerspective(img, M, (img.shape[1], img.shape[0]))# keep same size as input image\n",
    "    \n",
    "    return warped\n",
    "\n",
    "\n",
    "# Apply the above functions in succession and update the Rover state accordingly\n",
    "def perception_step(Rover):\n",
    "    # Perform perception steps to update Rover()\n",
    "    # TODO: \n",
    "    # NOTE: camera image is coming to you in Rover.img\n",
    "    # 1) Define source and destination points for perspective transform\n",
    "    # 2) Apply perspective transform\n",
    "    # 3) Apply color threshold to identify navigable terrain/obstacles/rock samples\n",
    "    # 4) Update Rover.vision_image (this will be displayed on left side of screen)\n",
    "        # Example: Rover.vision_image[:,:,0] = obstacle color-thresholded binary image\n",
    "        #          Rover.vision_image[:,:,1] = rock_sample color-thresholded binary image\n",
    "        #          Rover.vision_image[:,:,2] = navigable terrain color-thresholded binary image\n",
    "\n",
    "    # 5) Convert map image pixel values to rover-centric coords\n",
    "    # 6) Convert rover-centric pixel values to world coordinates\n",
    "    # 7) Update Rover worldmap (to be displayed on right side of screen)\n",
    "        # Example: Rover.worldmap[obstacle_y_world, obstacle_x_world, 0] += 1\n",
    "        #          Rover.worldmap[rock_y_world, rock_x_world, 1] += 1\n",
    "        #          Rover.worldmap[navigable_y_world, navigable_x_world, 2] += 1\n",
    "\n",
    "    # 8) Convert rover-centric pixel positions to polar coordinates\n",
    "    # Update Rover pixel distances and angles\n",
    "        # Rover.nav_dists = rover_centric_pixel_distances\n",
    "        # Rover.nav_angles = rover_centric_angles\n",
    "\n",
    "#     samplefile = '../misc/sample.jpg'    \n",
    "    samplefile = \"../calibration_images/example_rock1.jpg\"\n",
    "    image = mpimg.imread(samplefile)\n",
    "    dst_size = 10\n",
    "    bottom_offset = 6\n",
    "\n",
    "    # 1 - define source and destination points\n",
    "    source = np.float32([[14, 140], [301 ,140],[200, 96], [118, 96]])\n",
    "    destination = np.float32([[image.shape[1]/2 - dst_size, image.shape[0] - bottom_offset],\n",
    "                  [image.shape[1]/2 + dst_size, image.shape[0] - bottom_offset],\n",
    "                  [image.shape[1]/2 + dst_size, image.shape[0] - 2*dst_size - bottom_offset], \n",
    "                  [image.shape[1]/2 - dst_size, image.shape[0] - 2*dst_size - bottom_offset],\n",
    "                  ]) \n",
    "\n",
    "    scale = 10\n",
    "\n",
    "    # 2 - apply perspective transform\n",
    "    warped = perspect_transform(image, source, destination)\n",
    "\n",
    "    # 3 - apply color threshold\n",
    "    colorsel_obs, colorsel_rock, colorsel_nav = color_thresh(warped, rgb_thresh=(160, 160, 160))\n",
    "\n",
    "    # 4 - update Rover.vision image\n",
    "    Rover.vision_image[:,:,0] = colorsel_obs\n",
    "    Rover.vision_image[:,:,1] = colorsel_rock\n",
    "    Rover.vision_image[:,:,2] = colorsel_nav\n",
    "\n",
    "    # 5 - convert map image pixel values to rover centric coordinates\n",
    "    xpix, ypix = rover_coords(colorsel_obs)\n",
    "\n",
    "    # 6 - convert rover centric pixel values to world coordinates\n",
    "    x_world, y_world = pix_to_world(\n",
    "        xpix, ypix, Rover.pos[0], Rover.pos[1],\n",
    "        Rover.yaw, Rover.worldmap.shape[0], scale)\n",
    "\n",
    "    # 7 - update rover worldmap to be displayed\n",
    "    Rover.worldmap[x_world, y_world, 0] += 1\n",
    "\n",
    "    # 8 - convert rover centric pixel positions to polar coordinates\n",
    "    Rover.nav_dists, Rover.nav_angles = to_polar_coords(xpix, ypix)\n",
    "    \n",
    " \n",
    "    \n",
    "    \n",
    "    return Rover.vision_image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_result = perception_step(Rover)\n",
    "\n",
    "# plt.imshow(test_result)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12,3))\n",
    "plt.subplot(131)\n",
    "plt.imshow(test_result[:,:,0])\n",
    "plt.subplot(132)\n",
    "plt.imshow(test_result[:,:,1])\n",
    "plt.subplot(133)\n",
    "plt.imshow(test_result[:,:,2])\n",
    "\n",
    "\n",
    "# print (len(test_result))\n",
    "# print (test_result[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 320)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(colorsel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
